{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9ba139-8388-46f6-8ca7-7828e6974cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Science Books Dataset Cleaning  \n",
    "### [Amazon Data Science Books Dataset from Kaggle](https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books)  \n",
    "### Work done by: [@chusk2](https://twitter.com/chusk2)  \n",
    "### Github repository: [data_cleaning](https://github.com/chusk2/data_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784da3d-79e1-4480-ba96-94af3e679d8e",
   "metadata": {},
   "source": [
    "## Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c297ef99-c3db-482d-89f0-45bc7ce4219f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20597348-6115-4d58-8620-05057c15944b",
   "metadata": {},
   "source": [
    "## Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60712390-4e5c-4dd8-8176-9c3be7d047e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_science_books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fd13c-94b1-446a-abef-ce5cfdf70be8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First overlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49961fb1-e995-4a9c-a089-10c7d96a8de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>price (including used books)</th>\n",
       "      <th>pages</th>\n",
       "      <th>avg_reviews</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>weight</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>link</th>\n",
       "      <th>complete_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analysis Using R (Low Priced Edition): A ...</td>\n",
       "      <td>[ Dr Dhaval Maheta]</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>500</td>\n",
       "      <td>4.4</td>\n",
       "      <td>23</td>\n",
       "      <td>55%</td>\n",
       "      <td>39%</td>\n",
       "      <td>6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5 x 1.01 x 11 inches</td>\n",
       "      <td>2.53 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Notion Press Media Pvt Ltd (November 22, 2021)</td>\n",
       "      <td>978-1685549596</td>\n",
       "      <td>/Data-Analysis-Using-Low-Priced/dp/1685549594/...</td>\n",
       "      <td>https://www.amazon.com/Data-Analysis-Using-Low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Head First Data Analysis: A learner's guide to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.72</td>\n",
       "      <td>21.49 - 33.72</td>\n",
       "      <td>484</td>\n",
       "      <td>4.3</td>\n",
       "      <td>124</td>\n",
       "      <td>61%</td>\n",
       "      <td>20%</td>\n",
       "      <td>9%</td>\n",
       "      <td>4%</td>\n",
       "      <td>6%</td>\n",
       "      <td>8 x 0.98 x 9.25 inches</td>\n",
       "      <td>1.96 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition (August 18, 2009)</td>\n",
       "      <td>978-0596153939</td>\n",
       "      <td>/Head-First-Data-Analysis-statistics/dp/059615...</td>\n",
       "      <td>https://www.amazon.com/Head-First-Data-Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guerrilla Data Analysis Using Microsoft Excel:...</td>\n",
       "      <td>[ Oz du Soleil,  and , Bill Jelen]</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.07</td>\n",
       "      <td>274</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10</td>\n",
       "      <td>87%</td>\n",
       "      <td>13%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.25 x 0.6 x 10.75 inches</td>\n",
       "      <td>1.4 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Holy Macro! Books; Third edition (August 1, 2022)</td>\n",
       "      <td>978-1615470747</td>\n",
       "      <td>/Guerrilla-Analysis-Using-Microsoft-Excel/dp/1...</td>\n",
       "      <td>https://www.amazon.com/Guerrilla-Analysis-Usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python for Data Analysis: Data Wrangling with ...</td>\n",
       "      <td>[ William McKinney]</td>\n",
       "      <td>53.99</td>\n",
       "      <td>53.99</td>\n",
       "      <td>547</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1,686</td>\n",
       "      <td>75%</td>\n",
       "      <td>16%</td>\n",
       "      <td>5%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7 x 1.11 x 9.19 inches</td>\n",
       "      <td>1.47 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 2nd edition (November 14, 2017)</td>\n",
       "      <td>978-1491957660</td>\n",
       "      <td>/Python-Data-Analysis-Wrangling-IPython/dp/149...</td>\n",
       "      <td>https://www.amazon.com/Python-Data-Analysis-Wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excel Data Analysis For Dummies (For Dummies (...</td>\n",
       "      <td>[ Paul McFedries]</td>\n",
       "      <td>24.49</td>\n",
       "      <td>24.49</td>\n",
       "      <td>368</td>\n",
       "      <td>3.9</td>\n",
       "      <td>12</td>\n",
       "      <td>52%</td>\n",
       "      <td>17%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>7.38 x 0.83 x 9.25 inches</td>\n",
       "      <td>1.3 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>For Dummies; 5th edition (February 3, 2022)</td>\n",
       "      <td>978-1119844426</td>\n",
       "      <td>/Excel-Data-Analysis-Dummies-Computer/dp/11198...</td>\n",
       "      <td>https://www.amazon.com/Excel-Data-Analysis-Dum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Data Analysis Using R (Low Priced Edition): A ...   \n",
       "1  Head First Data Analysis: A learner's guide to...   \n",
       "2  Guerrilla Data Analysis Using Microsoft Excel:...   \n",
       "3  Python for Data Analysis: Data Wrangling with ...   \n",
       "4  Excel Data Analysis For Dummies (For Dummies (...   \n",
       "\n",
       "                               author  price price (including used books)  \\\n",
       "0                 [ Dr Dhaval Maheta]   6.75                         6.75   \n",
       "1                                 NaN  33.72               21.49 - 33.72    \n",
       "2  [ Oz du Soleil,  and , Bill Jelen]  32.07                        32.07   \n",
       "3                 [ William McKinney]  53.99                        53.99   \n",
       "4                   [ Paul McFedries]  24.49                        24.49   \n",
       "\n",
       "  pages  avg_reviews n_reviews star5 star4 star3 star2 star1  \\\n",
       "0   500          4.4        23   55%   39%    6%   NaN   NaN   \n",
       "1   484          4.3       124   61%   20%    9%    4%    6%   \n",
       "2   274          4.7        10   87%   13%   NaN   NaN   NaN   \n",
       "3   547          4.6     1,686   75%   16%    5%    2%    2%   \n",
       "4   368          3.9        12   52%   17%   10%   10%   10%   \n",
       "\n",
       "                  dimensions       weight language  \\\n",
       "0     8.5 x 1.01 x 11 inches  2.53 pounds  English   \n",
       "1     8 x 0.98 x 9.25 inches  1.96 pounds  English   \n",
       "2  8.25 x 0.6 x 10.75 inches   1.4 pounds  English   \n",
       "3     7 x 1.11 x 9.19 inches  1.47 pounds  English   \n",
       "4  7.38 x 0.83 x 9.25 inches   1.3 pounds  English   \n",
       "\n",
       "                                           publisher         ISBN_13  \\\n",
       "0     Notion Press Media Pvt Ltd (November 22, 2021)  978-1685549596   \n",
       "1      O'Reilly Media; 1st edition (August 18, 2009)  978-0596153939   \n",
       "2  Holy Macro! Books; Third edition (August 1, 2022)  978-1615470747   \n",
       "3    O'Reilly Media; 2nd edition (November 14, 2017)  978-1491957660   \n",
       "4        For Dummies; 5th edition (February 3, 2022)  978-1119844426   \n",
       "\n",
       "                                                link  \\\n",
       "0  /Data-Analysis-Using-Low-Priced/dp/1685549594/...   \n",
       "1  /Head-First-Data-Analysis-statistics/dp/059615...   \n",
       "2  /Guerrilla-Analysis-Using-Microsoft-Excel/dp/1...   \n",
       "3  /Python-Data-Analysis-Wrangling-IPython/dp/149...   \n",
       "4  /Excel-Data-Analysis-Dummies-Computer/dp/11198...   \n",
       "\n",
       "                                       complete_link  \n",
       "0  https://www.amazon.com/Data-Analysis-Using-Low...  \n",
       "1  https://www.amazon.com/Head-First-Data-Analysi...  \n",
       "2  https://www.amazon.com/Guerrilla-Analysis-Usin...  \n",
       "3  https://www.amazon.com/Python-Data-Analysis-Wr...  \n",
       "4  https://www.amazon.com/Excel-Data-Analysis-Dum...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f218e29-ba1c-4433-8e41-778281cf445f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'author', 'price', 'price (including used books)', 'pages',\n",
       "       'avg_reviews', 'n_reviews', 'star5', 'star4', 'star3', 'star2', 'star1',\n",
       "       'dimensions', 'weight', 'language', 'publisher', 'ISBN_13', 'link',\n",
       "       'complete_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e72271-0501-43be-8c75-afe10718e13c",
   "metadata": {},
   "source": [
    "# Dataset cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd4d68-eca0-4640-a0b3-6583f59cbd4d",
   "metadata": {},
   "source": [
    "## Subset of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234e9764-c457-44eb-adeb-56acf16e437f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = data['title, author, price, pages, language, publisher, ISBN_13, complete_link'.split(', ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b211737-7151-4681-be8d-489a9bf572d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'author', 'price', 'pages', 'language', 'publisher', 'ISBN_13',\n",
       "       'complete_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83926fa6-7210-4b62-8545-3a867d910ca1",
   "metadata": {},
   "source": [
    "## Clean `author`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7ede8c-b2c8-4768-82b3-ab87dbb1df28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ed451c-b9c4-4ba0-bde5-9af68b7f4191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_author(value):\n",
    "\tif value == value:\n",
    "\t\treturn value.lstrip('[ ').rstrip(']').replace(',  and ,', ' and')\n",
    "\telse:\n",
    "\t\treturn value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb1c636-d201-4aeb-9309-08708dfe8b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\code\\AppData\\Local\\Temp\\ipykernel_4536\\4174911401.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.author = df.author.apply(clean_author)\n"
     ]
    }
   ],
   "source": [
    "df.author = df.author.apply(clean_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf1e3ce-cce7-4cba-ad88-1933416239d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>pages</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>complete_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>The Handbook of Data Science and AI: Generate ...</td>\n",
       "      <td>Stefan Papp, Wolfgang Weidinger, et al.</td>\n",
       "      <td>42.49</td>\n",
       "      <td>576</td>\n",
       "      <td>English</td>\n",
       "      <td>Hanser Publications (April 28, 2022)</td>\n",
       "      <td>978-1569908860</td>\n",
       "      <td>https://www.amazon.com/Handbook-Data-Science-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>CompTIA Data+ Study Guide: Exam DA0-001</td>\n",
       "      <td>Mike Chapple and Sharif Nijim</td>\n",
       "      <td>34.49</td>\n",
       "      <td>368</td>\n",
       "      <td>English</td>\n",
       "      <td>Sybex; 1st edition (March 25, 2022)</td>\n",
       "      <td>978-1119845256</td>\n",
       "      <td>https://www.amazon.com/CompTIA-Data-Study-Guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Web Scraping with Python: Collecting More Data...</td>\n",
       "      <td>Ryan Mitchell</td>\n",
       "      <td>33.49</td>\n",
       "      <td>Parse complicated HTML</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 2nd edition (May 8, 2018)</td>\n",
       "      <td>978-1491985571</td>\n",
       "      <td>https://www.amazon.com/Web-Scraping-Python-Col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Data Science in Chemistry (De Gruyter Textbook)</td>\n",
       "      <td>Thorsten Gressling</td>\n",
       "      <td>52.64</td>\n",
       "      <td>330</td>\n",
       "      <td>English</td>\n",
       "      <td>De Gruyter (November 23, 2020)</td>\n",
       "      <td>978-3110629392</td>\n",
       "      <td>https://www.amazon.com/Data-Science-Chemistry-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>The Self-Taught Computer Scientist: The Beginn...</td>\n",
       "      <td>Cory Althoff</td>\n",
       "      <td>19.49</td>\n",
       "      <td>224</td>\n",
       "      <td>English</td>\n",
       "      <td>Wiley; 1st edition (October 1, 2021)</td>\n",
       "      <td>978-1119724414</td>\n",
       "      <td>https://www.amazon.com/Self-Taught-Computer-Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Learning R: A Step-by-Step Function Guide to D...</td>\n",
       "      <td>Richard Cotton</td>\n",
       "      <td>40.99</td>\n",
       "      <td>396</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition (October 22, 2013)</td>\n",
       "      <td>978-1449357108</td>\n",
       "      <td>https://www.amazon.com/Learning-Step-Step-Func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>The Data Revolution: A Critical Analysis of Bi...</td>\n",
       "      <td>Rob Kitchin</td>\n",
       "      <td>42.00</td>\n",
       "      <td>376</td>\n",
       "      <td>English</td>\n",
       "      <td>SAGE Publications Ltd; Second edition (May 31,...</td>\n",
       "      <td>The Data Revolution</td>\n",
       "      <td>https://www.amazon.com/Data-Revolution-Critica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Introduction to Statistics and Data Analysis</td>\n",
       "      <td>Roxy Peck, Chris Olsen, et al.</td>\n",
       "      <td>15.10</td>\n",
       "      <td>944</td>\n",
       "      <td>English</td>\n",
       "      <td>Brooks Cole; 5th edition (January 1, 2015)</td>\n",
       "      <td>978-1305267244</td>\n",
       "      <td>https://www.amazon.com/Introduction-Statistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Kafka: The Definitive Guide: Real-Time Data an...</td>\n",
       "      <td>Gwen Shapira, Todd Palino, et al.</td>\n",
       "      <td>31.99</td>\n",
       "      <td>488</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 2nd edition (November 30, 2021)</td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.com/Kafka-Definitive-Real-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Applied Geospatial Data Science with Python: T...</td>\n",
       "      <td>David Jordan</td>\n",
       "      <td>54.51</td>\n",
       "      <td>308</td>\n",
       "      <td>English</td>\n",
       "      <td>Packt Publishing - ebooks Account (January 10,...</td>\n",
       "      <td>978-1803238128</td>\n",
       "      <td>https://www.amazon.com/Applied-Geospatial-Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "784  The Handbook of Data Science and AI: Generate ...   \n",
       "65             CompTIA Data+ Study Guide: Exam DA0-001   \n",
       "543  Web Scraping with Python: Collecting More Data...   \n",
       "781    Data Science in Chemistry (De Gruyter Textbook)   \n",
       "655  The Self-Taught Computer Scientist: The Beginn...   \n",
       "291  Learning R: A Step-by-Step Function Guide to D...   \n",
       "233  The Data Revolution: A Critical Analysis of Bi...   \n",
       "149       Introduction to Statistics and Data Analysis   \n",
       "47   Kafka: The Definitive Guide: Real-Time Data an...   \n",
       "596  Applied Geospatial Data Science with Python: T...   \n",
       "\n",
       "                                      author  price                     pages  \\\n",
       "784  Stefan Papp, Wolfgang Weidinger, et al.  42.49                       576   \n",
       "65             Mike Chapple and Sharif Nijim  34.49                       368   \n",
       "543                            Ryan Mitchell  33.49  Parse complicated HTML     \n",
       "781                       Thorsten Gressling  52.64                       330   \n",
       "655                             Cory Althoff  19.49                       224   \n",
       "291                           Richard Cotton  40.99                       396   \n",
       "233                              Rob Kitchin  42.00                       376   \n",
       "149           Roxy Peck, Chris Olsen, et al.  15.10                       944   \n",
       "47         Gwen Shapira, Todd Palino, et al.  31.99                       488   \n",
       "596                             David Jordan  54.51                       308   \n",
       "\n",
       "    language                                          publisher  \\\n",
       "784  English               Hanser Publications (April 28, 2022)   \n",
       "65   English                Sybex; 1st edition (March 25, 2022)   \n",
       "543  English          O'Reilly Media; 2nd edition (May 8, 2018)   \n",
       "781  English                     De Gruyter (November 23, 2020)   \n",
       "655  English               Wiley; 1st edition (October 1, 2021)   \n",
       "291  English     O'Reilly Media; 1st edition (October 22, 2013)   \n",
       "233  English  SAGE Publications Ltd; Second edition (May 31,...   \n",
       "149  English         Brooks Cole; 5th edition (January 1, 2015)   \n",
       "47   English    O'Reilly Media; 2nd edition (November 30, 2021)   \n",
       "596  English  Packt Publishing - ebooks Account (January 10,...   \n",
       "\n",
       "                 ISBN_13                                      complete_link  \n",
       "784       978-1569908860  https://www.amazon.com/Handbook-Data-Science-A...  \n",
       "65        978-1119845256  https://www.amazon.com/CompTIA-Data-Study-Guid...  \n",
       "543       978-1491985571  https://www.amazon.com/Web-Scraping-Python-Col...  \n",
       "781       978-3110629392  https://www.amazon.com/Data-Science-Chemistry-...  \n",
       "655       978-1119724414  https://www.amazon.com/Self-Taught-Computer-Sc...  \n",
       "291       978-1449357108  https://www.amazon.com/Learning-Step-Step-Func...  \n",
       "233  The Data Revolution  https://www.amazon.com/Data-Revolution-Critica...  \n",
       "149       978-1305267244  https://www.amazon.com/Introduction-Statistics...  \n",
       "47                        https://www.amazon.com/Kafka-Definitive-Real-T...  \n",
       "596       978-1803238128  https://www.amazon.com/Applied-Geospatial-Data...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bbece-e02f-4454-9dd9-bd9d92e4d147",
   "metadata": {},
   "source": [
    "## Clean `pages`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675699c-371e-4df1-b235-704be1c22f12",
   "metadata": {},
   "source": [
    "There's an error when trying to convert prices to float:  \n",
    "`ValueError: could not convert string to float: 'Explores all feature...`  \n",
    "Some values content comments, so I need to clean the price columns first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29129977-219e-47ed-9662-9acd1caaf7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.pages.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0fca49-e303-4c51-a5d8-f76d43841799",
   "metadata": {},
   "source": [
    "I will figure out what's the maximum lenght of the figures in pages column. I will try to convert to float those values of a maximum length. If it raises an error, it means there are values that are strings. In that case, I try using a shorter length for figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8a00d-dbdb-4aed-84a7-ffaebc6dfc0f",
   "metadata": {},
   "source": [
    "Length 5 raises an error, but maximum length of pages figure of 4 doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2fe7ea1-ade0-4cbf-b8ee-6854e0a2a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.pages[df.pages.str.len() <=5].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5555b8-6f48-4284-97e4-b41dcc6dd0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      500.0\n",
       "1      484.0\n",
       "2      274.0\n",
       "3      547.0\n",
       "4      368.0\n",
       "       ...  \n",
       "822    165.0\n",
       "824    280.0\n",
       "825    208.0\n",
       "826    573.0\n",
       "827    288.0\n",
       "Name: pages, Length: 736, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pages[df.pages.str.len() <=4].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6bde07-e442-48ab-88e3-03db35e69f64",
   "metadata": {},
   "source": [
    "Now I know that values longer than 4 are comments. Shorter values correspond to pages number, so there won't be a comment (use NaN). With this information I create a column with comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad97ced6-74ec-4cd6-a597-aea9359c4879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\code\\AppData\\Local\\Temp\\ipykernel_4536\\3878540880.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comments'] = np.where(df.pages.str.len() >= 5, df.pages, np.nan)\n"
     ]
    }
   ],
   "source": [
    "df['comments'] = np.where(df.pages.str.len() >= 5, df.pages, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46419c90-e0c1-4af1-b9a8-6c29fb0061fd",
   "metadata": {},
   "source": [
    "Now let's finally clean the pages column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec72bf5-405e-4fb4-b81e-25a4af6161c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\code\\AppData\\Local\\Temp\\ipykernel_4536\\108972310.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.pages = np.where(df.pages.str.len() <= 4, df.pages, np.nan).astype(float)\n"
     ]
    }
   ],
   "source": [
    "df.pages = np.where(df.pages.str.len() <= 4, df.pages, np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9764b855-73d9-4371-8b4f-4f29bd17ed18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>pages</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>complete_link</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Responsible Data Science: Transparency and Fai...</td>\n",
       "      <td>Peter C. Bruce and Grant Fleming</td>\n",
       "      <td>19.89</td>\n",
       "      <td>304.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Wiley; 1st edition (May 11, 2021)</td>\n",
       "      <td>59</td>\n",
       "      <td>https://www.amazon.com/Responsible-Data-Scienc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Democracy's Data: The Hidden Stories in the U....</td>\n",
       "      <td>Dan Bouk</td>\n",
       "      <td>25.49</td>\n",
       "      <td>384.0</td>\n",
       "      <td>English</td>\n",
       "      <td>MCD (August 23, 2022)</td>\n",
       "      <td>978-0374602543</td>\n",
       "      <td>https://www.amazon.com/Democracys-Data-Hidden-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>The Python Bible Volume 5: Python For Finance ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.99</td>\n",
       "      <td>58.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Independently published (August 14, 2019)</td>\n",
       "      <td>978-1686407376</td>\n",
       "      <td>https://www.amazon.com/Python-Bible-Finance-An...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>The Dropout Multi-Millionaire: 37 Business Les...</td>\n",
       "      <td>Brian  WIll</td>\n",
       "      <td>0.99</td>\n",
       "      <td>162.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Bookmark Publishing House (April 30, 2021)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/Dropout-Multi-Millionai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Excel Formulas (Quick Study Computer)</td>\n",
       "      <td>Inc. BarCharts</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.0</td>\n",
       "      <td>English</td>\n",
       "      <td>QuickStudy; Lam Rfc Cr edition (December 31, 2...</td>\n",
       "      <td>978-1423221692</td>\n",
       "      <td>https://www.amazon.com/Excel-Formulas-Quick-St...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "698  Responsible Data Science: Transparency and Fai...   \n",
       "660  Democracy's Data: The Hidden Stories in the U....   \n",
       "500  The Python Bible Volume 5: Python For Finance ...   \n",
       "245  The Dropout Multi-Millionaire: 37 Business Les...   \n",
       "271              Excel Formulas (Quick Study Computer)   \n",
       "\n",
       "                               author  price  pages language  \\\n",
       "698  Peter C. Bruce and Grant Fleming  19.89  304.0  English   \n",
       "660                          Dan Bouk  25.49  384.0  English   \n",
       "500                               NaN   7.99   58.0  English   \n",
       "245                       Brian  WIll   0.99  162.0  English   \n",
       "271                    Inc. BarCharts   5.95    6.0  English   \n",
       "\n",
       "                                             publisher         ISBN_13  \\\n",
       "698                  Wiley; 1st edition (May 11, 2021)              59   \n",
       "660                              MCD (August 23, 2022)  978-0374602543   \n",
       "500          Independently published (August 14, 2019)  978-1686407376   \n",
       "245         Bookmark Publishing House (April 30, 2021)             NaN   \n",
       "271  QuickStudy; Lam Rfc Cr edition (December 31, 2...  978-1423221692   \n",
       "\n",
       "                                         complete_link comments  \n",
       "698  https://www.amazon.com/Responsible-Data-Scienc...      NaN  \n",
       "660  https://www.amazon.com/Democracys-Data-Hidden-...      NaN  \n",
       "500  https://www.amazon.com/Python-Bible-Finance-An...      NaN  \n",
       "245  https://www.amazon.com/Dropout-Multi-Millionai...      NaN  \n",
       "271  https://www.amazon.com/Excel-Formulas-Quick-St...      NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a0ad2-b639-4264-b580-71a68520f870",
   "metadata": {},
   "source": [
    "## Clean `language`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a942aa8-29e7-468a-8dd9-4b1ee4bf4bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', nan, 'Spanish',\n",
       "       'Unqualified, Japanese (Dolby Digital 2.0 Mono), English (Dolby Digital 5.1), English (Dolby Digital 2.0 Mono)',\n",
       "       'you will discover all you need ',\n",
       "       '• How to make better business decisions using ',\n",
       "       'Concepts are presented in a \"to-the-point\" style to cater to the busy individual. With this book, you can learn Python in just one day and start coding immediately. ',\n",
       "       'standard library',\n",
       "       'This Python programming guide assumes certain level of programming knowledge. It is not a beginner textbook.',\n",
       "       'Scroll to the top of the page and click the ',\n",
       "       'English (Dolby Digital 2.0 Mono)',\n",
       "       'English (DTS-HD Master Audio 5.1), French (DTS-HD 2.0)',\n",
       "       '\"Brilliant.\"'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a33e4f-6967-4d9a-b451-9a1b1e8b2e91",
   "metadata": {},
   "source": [
    "Some values have `English` or `Spanish` as language values. Some others have languages with other comments. Other values are just comments. This needs a more deep cleaning than previous columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea031c7c-4bd3-4fbe-a0aa-1d6d959350ae",
   "metadata": {},
   "source": [
    "`language` values that don't have English, Spanish, Japanese or French, will be considered as comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84318391-4a72-4980-831d-a01c0745e025",
   "metadata": {},
   "source": [
    "Multiple conditions to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c9f13f-30f1-4d99-8855-fbae5b0a350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_english = df.language.str.contains('English')\n",
    "contains_spanish = df.language.str.contains('Spanish')\n",
    "contains_japanese = df.language.str.contains('Japanese')\n",
    "contains_french = df.language.str.contains('French')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c5fc6-6d15-4809-8baa-940223948ad5",
   "metadata": {},
   "source": [
    "Extract all the values that don't contain information about language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5f69f94-e72a-4c4d-938d-e720e465985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_language_info = ~(contains_english | contains_spanish | contains_japanese | contains_french | df.language.isnull() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfd98389-67bd-4260-b85a-cb3a884ad903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54                       you will discover all you need \n",
       "290       • How to make better business decisions using \n",
       "381    Concepts are presented in a \"to-the-point\" sty...\n",
       "382                                     standard library\n",
       "476    This Python programming guide assumes certain ...\n",
       "492         Scroll to the top of the page and click the \n",
       "633                                         \"Brilliant.\"\n",
       "Name: language, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language[not_language_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d8879-1394-4b13-aa06-328365b7b250",
   "metadata": {},
   "source": [
    "I will store the indexes of these rows, which do not contain some language information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5abe7404-5bfb-467a-94b7-c24796486dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_lang_indexes = df.language[not_language_info].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d141838-4eff-4494-b01e-435ffe8f8d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([54, 290, 381, 382, 476, 492, 633], dtype='int64')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_lang_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfa309-5ae0-40a8-a670-26bdacf2425b",
   "metadata": {},
   "source": [
    "Now I will create a function to add these comments to the comments column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029684ae-2342-4a02-b94c-4cc777d1c4ab",
   "metadata": {},
   "source": [
    "Check if these rows have already a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3106dec5-eb3a-4581-923c-8e6e1a634ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54       NaN\n",
       "290      NaN\n",
       "381      NaN\n",
       "382    1,000\n",
       "476      NaN\n",
       "492      NaN\n",
       "633      NaN\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[not_lang_indexes].comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef852486-71de-463a-95cd-71fbb76136c4",
   "metadata": {},
   "source": [
    "I have just discovered that row 382 had a valid number of pages:  1000 pages. I sent his page number to comments. I will fix this before going further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "321c7aee-ded2-43f0-b418-69d9a1c4e52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[382, ['pages']] = 1000\n",
    "df.loc[382, ['comments']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab9e233d-0a53-4645-9c05-a04be39bcdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            Python 3: The Comprehensive Guide to Hands-On ...\n",
       "author                           Johannes Ernesti and Peter Kaiser\n",
       "price                                                        55.48\n",
       "pages                                                       1000.0\n",
       "language                                          standard library\n",
       "publisher        Rheinwerk Computing; First edition (September ...\n",
       "ISBN_13                                             978-1493223022\n",
       "complete_link    https://www.amazon.com/gp/slredirect/picassoRe...\n",
       "comments                                                       NaN\n",
       "Name: 382, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0263039-89cb-405d-8cf6-bbcb484cb67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54     NaN\n",
       "290    NaN\n",
       "381    NaN\n",
       "382    NaN\n",
       "476    NaN\n",
       "492    NaN\n",
       "633    NaN\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[not_lang_indexes].comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbca003-0091-40fa-8945-42582cfa5f1b",
   "metadata": {},
   "source": [
    "Their comments values are NaN, so I will replace the with their values in column `language`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cf9a75b-14d9-43ee-a004-61436b9d1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[not_lang_indexes].comments = df.loc[not_lang_indexes].language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9956517-8146-49e9-9ce8-67be4dde98a1",
   "metadata": {},
   "source": [
    "Remove the comments from the `language` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29c36e98-222b-4936-ac9d-000e9003ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[not_lang_indexes, ['language']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e72460-0848-4ce5-b841-f6cfe7ab3464",
   "metadata": {},
   "source": [
    "Now let's process the rest of the language values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7386b761-8aab-4713-b0d4-0537db711cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', nan, 'Spanish',\n",
       "       'Unqualified, Japanese (Dolby Digital 2.0 Mono), English (Dolby Digital 5.1), English (Dolby Digital 2.0 Mono)',\n",
       "       'English (Dolby Digital 2.0 Mono)',\n",
       "       'English (DTS-HD Master Audio 5.1), French (DTS-HD 2.0)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d78a7-4709-473a-9f7e-25837ecf1c91",
   "metadata": {},
   "source": [
    "There are only three types of language values which need cleaning, so I will create a function to clean them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da56241f-94ac-452f-abda-040c23aa323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_language(row):\n",
    "\tlang = row.language\n",
    "\tcomment = row.comments\n",
    "\tif lang == 'Unqualified, Japanese (Dolby Digital 2.0 Mono), English (Dolby Digital 5.1), English (Dolby Digital 2.0 Mono)' :\n",
    "\t\trow.language = 'English, Japanese'\n",
    "\t\tif comment != comment:  #check if comment is NaN\n",
    "\t\t\trow.comments = 'Avaliable languages: Japanese (Dolby Digital 2.0 Mono), English (Dolby Digital 5.1), English (Dolby Digital 2.0 Mono)'\n",
    "\t\telse:\n",
    "\t\t\trow.comments += ' Avaliable languages: Japanese (Dolby Digital 2.0 Mono), English (Dolby Digital 5.1), English (Dolby Digital 2.0 Mono)'\n",
    "\t\n",
    "\telif lang == 'English (Dolby Digital 2.0 Mono)' :\n",
    "\t\trow.language = 'English'\n",
    "\t\tif comment != comment:\n",
    "\t\t\trow.comments = 'English (Dolby Digital 2.0 Mono)'\n",
    "\t\telse:\n",
    "\t\t\trow.comments += 'English (Dolby Digital 2.0 Mono)'\n",
    "\t\n",
    "\telif lang == 'English (DTS-HD Master Audio 5.1), French (DTS-HD 2.0)' :\n",
    "\t\trow.language = 'English, French'\n",
    "\t\tif comment != comment :\n",
    "\t\t\trow.comments = 'English (DTS-HD Master Audio 5.1), French (DTS-HD 2.0)'\n",
    "\t\telse:\n",
    "\t\t\trow.comments += ' English (DTS-HD Master Audio 5.1), French (DTS-HD 2.0)'\n",
    "\treturn row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e21851ba-36f5-4185-a74f-9d4c9f720c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(clean_language, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac74903-1dd9-4f85-aab6-e4a8b2f97e74",
   "metadata": {},
   "source": [
    "Now the `language` column is clean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "934803cb-5f37-4069-b372-43857ac2071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', nan, 'Spanish', 'English, Japanese', 'English, French'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fca12-4ea5-4f93-90b7-c322303dfe08",
   "metadata": {},
   "source": [
    "## Clean `publisher`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a813d0f-d334-413a-8ce0-f4af8fa38af9",
   "metadata": {},
   "source": [
    "I want to extract the date of publishing and create a new `publishing_date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5001d571-fe66-4693-920a-30f9bcdc583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Notion Press Media Pvt Ltd (November 22, 2021)\n",
       "1          O'Reilly Media; 1st edition (August 18, 2009)\n",
       "2      Holy Macro! Books; Third edition (August 1, 2022)\n",
       "3        O'Reilly Media; 2nd edition (November 14, 2017)\n",
       "4            For Dummies; 5th edition (February 3, 2022)\n",
       "                             ...                        \n",
       "825            Corwin; First edition (December 15, 2017)\n",
       "826        Springer; 1st ed. 2020 edition (July 2, 2020)\n",
       "827                      Packt Publishing (July 8, 2022)\n",
       "828                                                  NaN\n",
       "829                                                  NaN\n",
       "Name: publisher, Length: 830, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d425941-82db-4246-bcd8-2894618c08d3",
   "metadata": {},
   "source": [
    "Create a function to extract the publishing date from the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b95c79a-6aff-4512-ac93-a53347aeb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(value):\n",
    "\tif value == value: \n",
    "\t\tsplited_value = value.split(' (')\n",
    "\t\t# date is the 2nd value of the list. \n",
    "\t\t# Furthermore, drop the closing parenthesis using [:-1]\n",
    "\t\tif len(splited_value) == 2:\n",
    "\t\t\tpublisher = splited_value[0]\n",
    "\t\t\tdate = splited_value[1][:-1]\n",
    "\t\t\treturn [publisher, date]\n",
    "\t\telse:\n",
    "\t\t\treturn 'invalid data'\n",
    "\telse:\n",
    "\t\treturn np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "246ed611-f9bb-44d3-82b8-682387df53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_info = df.publisher.apply(extract_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3930f97e-d715-4145-87db-a13fc79dabc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      [O'Reilly Media; 1st edition, August 18, 2009]\n",
       "587    [For Dummies; 1st edition, September 14, 2006]\n",
       "43                  [Packt Publishing, June 30, 2022]\n",
       "207        [Apress; 1st ed. edition, January 4, 2023]\n",
       "93              [Kenneth M Fornari, October 11, 2022]\n",
       "Name: publisher, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_info.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba56eb2-e356-4588-a9e7-4deecf0e978f",
   "metadata": {},
   "source": [
    "I will check if there are any invalid values, in order to investigate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "033a06e8-9469-4984-be39-bd6058c8b946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174    invalid data\n",
       "374    invalid data\n",
       "586    invalid data\n",
       "Name: publisher, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_info [publish_info == 'invalid data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b7d6d-863f-40f8-9bf4-6156b8e578ce",
   "metadata": {},
   "source": [
    "They are just three values, so there's no need to create a function. I will extract the date manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfee438d-a5fc-40d9-96b0-e1c03aa8324b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real Python (realpython.com); 4th edition (August 30, 2022)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[374].publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aff4a92b-f634-44f7-af1f-807be59f2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[374, ['publisher']] = 'Real Python - realpython.com - 4th edition (August 30, 2022)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6e801-c2e3-42c1-b680-29a7638d1312",
   "metadata": {},
   "source": [
    "<hr style='color: green'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d1f60f8-7562-46c8-a46b-23c21776756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real Python (realpython.com) (May 5, 2021)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[586].publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54234a66-030a-41ce-adb8-2097bc29effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[586, ['publisher']] = 'Real Python realpython.com (May 5, 2021)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce718994-3484-4c2f-8921-e74c9bf98068",
   "metadata": {},
   "source": [
    "<hr style='color: green'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2d0d4f8-506c-4684-9304-ef45d2875eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publisher    ;\n",
       "Name: 174, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[174, ['publisher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3f146c7-6c71-4263-a7a3-7b61e2d0b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[174, ['publisher']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d04739-205b-4749-8fb7-ea021a30c9c2",
   "metadata": {},
   "source": [
    "Once the three anormal data have been processed, I will apply the `extract_date` function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52034d10-f6dd-4375-8e49-b676cbc8dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_info = df.publisher.apply(extract_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e44908c-7515-480f-bd11-e203f94039ec",
   "metadata": {},
   "source": [
    "I create a new column: `publishing_date` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "610ef393-c8ff-4c5d-bbc6-5875907cbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publishing_date'] = [i[1] if (i==i) else i for i in publish_info  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "333e0285-fcfd-4ec6-8480-ce0f1c6eda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.publishing_date = pd.to_datetime(df.publishing_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8798c-81ff-4f5c-a618-bbb50c8f36af",
   "metadata": {},
   "source": [
    "Now I replace the `publisher` values with the processed publisher information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ba612bd-d4bf-4326-a255-9aa0b867accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publisher'] = [i[0] if (i==i) else i for i in publish_info  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "208ff443-9971-40a1-a4d0-61cab6188934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Notion Press Media Pvt Ltd\n",
       "1           O'Reilly Media; 1st edition\n",
       "2      Holy Macro! Books; Third edition\n",
       "3           O'Reilly Media; 2nd edition\n",
       "4              For Dummies; 5th edition\n",
       "                     ...               \n",
       "825               Corwin; First edition\n",
       "826      Springer; 1st ed. 2020 edition\n",
       "827                    Packt Publishing\n",
       "828                                 NaN\n",
       "829                                 NaN\n",
       "Name: publisher, Length: 830, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d906290-96d5-4717-90fe-d891e1c1bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.publisher = df.publisher.str.replace(';', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06bc0246-1a66-404b-9f44-1cbc5abf59a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712                               Packt Publishing\n",
       "686                           Pearson, 4th edition\n",
       "574                                No Starch Press\n",
       "466                                            NaN\n",
       "787    Dover Publications, 2nd Revised ed. edition\n",
       "142                               Packt Publishing\n",
       "356                               Packt Publishing\n",
       "149                       Brooks Cole, 5th edition\n",
       "309                         Routledge, 3rd edition\n",
       "253                                            NaN\n",
       "Name: publisher, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.publisher.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9627432-25c7-4a83-b43a-b2909dbbd2f1",
   "metadata": {},
   "source": [
    "## Clean `ISBN_13`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7e703-4ca0-4913-9a2f-864044b6c01a",
   "metadata": {},
   "source": [
    "It seems like some `ISBN_13` values are empty but not set as NaN. Aslo, lenght of ISBN_13 code must be 14 (13 + hyphen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "217746ee-d086-4225-bfa3-16a90465fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5                              NaN\n",
       "7      Research in Drama Education\n",
       "12                             NaN\n",
       "13                                \n",
       "14                                \n",
       "                  ...             \n",
       "824                             99\n",
       "825                             59\n",
       "826                               \n",
       "828                            NaN\n",
       "829                               \n",
       "Name: ISBN_13, Length: 369, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ISBN_13 [ df.ISBN_13.str.len() != 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a97730db-abf6-4831-b9bc-5647b3056693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Research in Drama Education', ' ', '$13.99 ', '-34%',\n",
       "       '     ', 'Usually ships within 2 to 3 days.', '#NAME?', '#250 in ',\n",
       "       '#1 in ', '  Second Edition, Second edition ', '$113.19 ', '-22%',\n",
       "       'The Data Revolution',\n",
       "       'Regulating Alcohol around the World: Policy Cocktails', '-19%',\n",
       "       '#35 in ', 'x', '-27%', '79', '99', '-21%', '75', '49', '69', '29',\n",
       "       '66', '-30%', '  Kindle Edition ', '$139.99 ', '$13.79 ', 'Python',\n",
       "       '#372 in ', 'PennyLane', 'JOSH TYSON', '—', '-39%', '59', '39',\n",
       "       '-25%', '30', '56', '25'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ISBN_13 [ df.ISBN_13.str.len() != 14].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c184c-72f0-41ba-811e-4813c230324b",
   "metadata": {},
   "source": [
    "First set empty values to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33299b23-55cb-4b07-bbb0-225febaea861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ISBN_13 = np.where((df.ISBN_13 == '') | (df.ISBN_13 == ' '), np.nan, df.ISBN_13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2de67-4d88-495d-a2b5-c56e713d02b3",
   "metadata": {},
   "source": [
    "Check if row with invalid ISBN_13 values have already comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aacd91d4-7ed1-42ec-a03b-99437daa79b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Research in Drama Education', '$13.99 ', '-34%', '     ',\n",
       "       'Usually ships within 2 to 3 days.', '#NAME?', '#250 in ',\n",
       "       '#1 in ', '  Second Edition, Second edition ', '$113.19 ', '-22%',\n",
       "       'The Data Revolution',\n",
       "       'Regulating Alcohol around the World: Policy Cocktails', '-19%',\n",
       "       '#35 in ', 'x', '-27%', '79', '99', '-21%', '75', '49', '69', '29',\n",
       "       '66', '-30%', '  Kindle Edition ', '$139.99 ', '$13.79 ', 'Python',\n",
       "       '#372 in ', 'PennyLane', 'JOSH TYSON', '—', '-39%', '59', '39',\n",
       "       '-25%', '30', '56', '25'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ISBN_13 [ df.ISBN_13.str.len() != 14].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7ce0d8e-dcfe-4aab-9406-9b158d83a501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invalid_isbn_values = list(df.ISBN_13 [ df.ISBN_13.str.len() != 14].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64ee5b8d-2873-4774-b666-978ebe2b4a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 'Research in Drama Education', '$13.99 ', '-34%', '     ']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_isbn_values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c534e31-cad4-44bd-a76d-7ef1946cce7d",
   "metadata": {},
   "source": [
    "Let's drop the nan values from invalid isbn values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7aff83d-0ff3-41be-914e-7e58900694e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invalid_isbn_values = invalid_isbn_values[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133733f5-cf8a-4557-8939-f7adfcb6fa8f",
   "metadata": {},
   "source": [
    "Let's check if the rows with prices in the `ISBN_13` column have the price set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74de1557-78f8-4cea-8ffa-2f3773cce6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>31</th>\n",
       "      <th>61</th>\n",
       "      <th>80</th>\n",
       "      <th>91</th>\n",
       "      <th>121</th>\n",
       "      <th>134</th>\n",
       "      <th>138</th>\n",
       "      <th>161</th>\n",
       "      <th>195</th>\n",
       "      <th>...</th>\n",
       "      <th>725</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>763</th>\n",
       "      <th>787</th>\n",
       "      <th>796</th>\n",
       "      <th>819</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>90.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>26.49</td>\n",
       "      <td>121.99</td>\n",
       "      <td>31.3</td>\n",
       "      <td>26.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.95</td>\n",
       "      <td>113.19</td>\n",
       "      <td>...</td>\n",
       "      <td>14.19</td>\n",
       "      <td>41.16</td>\n",
       "      <td>14.99</td>\n",
       "      <td>15.3</td>\n",
       "      <td>139.56</td>\n",
       "      <td>11.89</td>\n",
       "      <td>46.5</td>\n",
       "      <td>24.95</td>\n",
       "      <td>9.69</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN_13</th>\n",
       "      <td>Research in Drama Education</td>\n",
       "      <td>$13.99</td>\n",
       "      <td>-34%</td>\n",
       "      <td></td>\n",
       "      <td>Usually ships within 2 to 3 days.</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>#250 in</td>\n",
       "      <td>#1 in</td>\n",
       "      <td>Second Edition, Second edition</td>\n",
       "      <td>$113.19</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>-25%</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>-22%</td>\n",
       "      <td>25</td>\n",
       "      <td>99</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 7        31     61      80   \\\n",
       "price                           90.0    13.99  26.49  121.99   \n",
       "ISBN_13  Research in Drama Education  $13.99    -34%           \n",
       "\n",
       "                                       91      121       134     138  \\\n",
       "price                                 31.3   26.44       NaN     NaN   \n",
       "ISBN_13  Usually ships within 2 to 3 days.  #NAME?  #250 in   #1 in    \n",
       "\n",
       "                                       161       195  ...    725    730  \\\n",
       "price                                24.95    113.19  ...  14.19  41.16   \n",
       "ISBN_13    Second Edition, Second edition   $113.19   ...     39   -25%   \n",
       "\n",
       "           731   732     763    787   796    819   824   825  \n",
       "price    14.99  15.3  139.56  11.89  46.5  24.95  9.69  5.33  \n",
       "ISBN_13     99    30      56     69  -22%     25    99    59  \n",
       "\n",
       "[2 rows x 56 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['price', 'ISBN_13']][df.ISBN_13.isin(invalid_isbn_values)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba0a97-01f0-4b73-983c-37efbc0ea072",
   "metadata": {},
   "source": [
    "At the sight of the results, besides a couple of rows,the rest of the ISBN invalid values are not worth processing. I will just set them as NaN.  \n",
    "I will process the rows number: 7, 161, 233 and 292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e5c5027-5457-4b74-8772-f857b9b274d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qualitative Data Analysis: A Methods Sourcebook</td>\n",
       "      <td>Research in Drama Education</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Guerrilla Data Analysis Using Microsoft Excel:...</td>\n",
       "      <td>Second Edition, Second edition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>The Data Revolution: A Critical Analysis of Bi...</td>\n",
       "      <td>The Data Revolution</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>An Introduction to Data Analysis: Quantitative...</td>\n",
       "      <td>Regulating Alcohol around the World: Policy Co...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "7      Qualitative Data Analysis: A Methods Sourcebook   \n",
       "161  Guerrilla Data Analysis Using Microsoft Excel:...   \n",
       "233  The Data Revolution: A Critical Analysis of Bi...   \n",
       "292  An Introduction to Data Analysis: Quantitative...   \n",
       "\n",
       "                                               ISBN_13 comments  \n",
       "7                          Research in Drama Education      NaN  \n",
       "161                    Second Edition, Second edition       NaN  \n",
       "233                                The Data Revolution      NaN  \n",
       "292  Regulating Alcohol around the World: Policy Co...      NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[7,161,233,292], ['title', 'ISBN_13', 'comments'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ab70f-3021-4a64-93b2-8ebf825ab26f",
   "metadata": {},
   "source": [
    "It seems like book in row 292 has an ISBN value that has nothing to do this its title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6bf22628-8629-49a9-9e1d-fa2d15526090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['An Introduction to Data Analysis: Quantitative, Qualitative and Mixed Methods'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[292, ['title']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d12fc6fb-827d-47bc-b044-f906a6d32b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regulating Alcohol around the World: Policy Cocktails'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[292, 'ISBN_13']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1986ba3-6e13-4a5e-9e9b-7aaaffa18e61",
   "metadata": {},
   "source": [
    "I will clean manually these 4 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "745053cc-70ae-472a-9526-e037b4be5cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[7, 'comments'] = 'Research in Drama Education'\n",
    "df.loc[161, 'ISBN_13'] = 'Second edition'\n",
    "df.loc[[233, 292], 'ISBN_13'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914bc11-a906-426f-8878-e7e966e5612e",
   "metadata": {},
   "source": [
    "The rest of invalid ISBN values will be set to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c63a4c8-d076-4b9c-92cf-1621a3183fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>31</th>\n",
       "      <th>61</th>\n",
       "      <th>80</th>\n",
       "      <th>91</th>\n",
       "      <th>121</th>\n",
       "      <th>134</th>\n",
       "      <th>138</th>\n",
       "      <th>195</th>\n",
       "      <th>217</th>\n",
       "      <th>...</th>\n",
       "      <th>725</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>763</th>\n",
       "      <th>787</th>\n",
       "      <th>796</th>\n",
       "      <th>819</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>90.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>26.49</td>\n",
       "      <td>121.99</td>\n",
       "      <td>31.3</td>\n",
       "      <td>26.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.19</td>\n",
       "      <td>46.53</td>\n",
       "      <td>...</td>\n",
       "      <td>14.19</td>\n",
       "      <td>41.16</td>\n",
       "      <td>14.99</td>\n",
       "      <td>15.3</td>\n",
       "      <td>139.56</td>\n",
       "      <td>11.89</td>\n",
       "      <td>46.5</td>\n",
       "      <td>24.95</td>\n",
       "      <td>9.69</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN_13</th>\n",
       "      <td>Research in Drama Education</td>\n",
       "      <td>$13.99</td>\n",
       "      <td>-34%</td>\n",
       "      <td></td>\n",
       "      <td>Usually ships within 2 to 3 days.</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>#250 in</td>\n",
       "      <td>#1 in</td>\n",
       "      <td>$113.19</td>\n",
       "      <td>-22%</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>-25%</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>-22%</td>\n",
       "      <td>25</td>\n",
       "      <td>99</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 7        31     61      80   \\\n",
       "price                           90.0    13.99  26.49  121.99   \n",
       "ISBN_13  Research in Drama Education  $13.99    -34%           \n",
       "\n",
       "                                       91      121       134     138  \\\n",
       "price                                 31.3   26.44       NaN     NaN   \n",
       "ISBN_13  Usually ships within 2 to 3 days.  #NAME?  #250 in   #1 in    \n",
       "\n",
       "              195    217  ...    725    730    731   732     763    787   796  \\\n",
       "price      113.19  46.53  ...  14.19  41.16  14.99  15.3  139.56  11.89  46.5   \n",
       "ISBN_13  $113.19    -22%  ...     39   -25%     99    30      56     69  -22%   \n",
       "\n",
       "           819   824   825  \n",
       "price    24.95  9.69  5.33  \n",
       "ISBN_13     25    99    59  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['price', 'ISBN_13']][df.ISBN_13.isin(invalid_isbn_values)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d2c6541-e723-47c8-9945-41fa53d94920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.ISBN_13.isin(invalid_isbn_values), 'ISBN_13'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9d59f-ed65-454d-b3a7-d063bcdf8bf6",
   "metadata": {},
   "source": [
    "I check ISBN values again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56e75cfc-615e-47dd-91bd-89771251efef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Second edition', 'Pratip Samanta']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df['ISBN_13'].dropna().unique() if not i.startswith('9')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04120844-9cb0-417f-bc3d-d3b10501b87d",
   "metadata": {},
   "source": [
    "A couple of rows still need a cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e719b58c-93f9-4d8f-8ca6-6714b7e0bd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invalid_isbn_values = [i for i in df['ISBN_13'].dropna().unique() if not i.startswith('9')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4cf75ef2-0b2d-4fbe-9141-b1994ff11a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Second edition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Pratip Samanta</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISBN_13 comments\n",
       "161  Second edition      NaN\n",
       "427  Pratip Samanta      NaN"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ISBN_13', 'comments']][df.ISBN_13.isin(invalid_isbn_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0eb4d43d-55d5-4dfe-8941-07829aaff2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[[161, 427], 'comments'] = df.loc[[161, 427], 'ISBN_13']\n",
    "df.loc[[161, 427], 'ISBN_13'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13358c0-9bb6-4a41-8073-e299d19ac2f7",
   "metadata": {},
   "source": [
    "Finally ISBN column is clean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "827ade07-014e-40cf-9bcb-b9204a676c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df['ISBN_13'].dropna().unique() if not i.startswith('9')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "512c43c3-4b76-4cdc-9f31-b758b28e61ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606    979-8364281784\n",
       "752    978-0525509202\n",
       "322               NaN\n",
       "358               NaN\n",
       "117               NaN\n",
       "36     978-1718502208\n",
       "669               NaN\n",
       "708    978-0198862758\n",
       "827    978-1803241333\n",
       "424               NaN\n",
       "9      978-1617296055\n",
       "778    978-0984782857\n",
       "666               NaN\n",
       "277    978-1473756540\n",
       "783               NaN\n",
       "Name: ISBN_13, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ISBN_13.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8301279-1158-4116-8b80-5bf96594973e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine tuning of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ce8e9aa-c00a-4501-94d4-a93853bbc7ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def lower_words(title_string):\n",
    "    words_to_lower = ['Using', 'And', 'For']\n",
    "    for word in words_to_lower:\n",
    "        if word in title_string:\n",
    "            title_string = title_string.replace(word, word.lower())\n",
    "    return title_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "206f707e-bb49-41b1-bb1c-23075a78b236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.title = df.title.apply(lower_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295681c3-d805-4c73-928d-925220f22121",
   "metadata": {},
   "source": [
    "## Reorder dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91ef0c-0ceb-499d-8bc3-eaec17864a6c",
   "metadata": {},
   "source": [
    "A final reorder of the columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0be84dc-42b2-4c30-be66-eec682ebf368",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['title', 'author', 'publisher', 'publishing_date', 'pages', 'price', 'language', 'ISBN_13', 'complete_link', 'comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7b9934b-471f-4b12-a8ca-cac291f0ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(new_order, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1ddd1-aad5-4472-8504-8ac7e6ce8ee2",
   "metadata": {},
   "source": [
    "Finally, get a sample to have an overview of the clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad6ccc7a-689d-466b-974b-0feb058e457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishing_date</th>\n",
       "      <th>pages</th>\n",
       "      <th>price</th>\n",
       "      <th>language</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>complete_link</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Continuous Delivery with Docker and Jenkins: C...</td>\n",
       "      <td>Rafal Leszko</td>\n",
       "      <td>Packt Publishing, 2nd edition</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>350.0</td>\n",
       "      <td>46.99</td>\n",
       "      <td>English</td>\n",
       "      <td>978-1838552183</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Data Science Crash Course for Beginners with P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Publishing LLC</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>314.0</td>\n",
       "      <td>23.48</td>\n",
       "      <td>English</td>\n",
       "      <td>978-1734790146</td>\n",
       "      <td>https://www.amazon.com/Science-Crash-Course-Be...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Data Quality Fundamentals: A Practitioner's Gu...</td>\n",
       "      <td>Barr Moses, Lior Gavish, et al.</td>\n",
       "      <td>O'Reilly Media, 1st edition</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>308.0</td>\n",
       "      <td>46.99</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/Data-Quality-Fundamenta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Introduction to Probability for Data Science</td>\n",
       "      <td>Stanley Chan</td>\n",
       "      <td>Michigan Publishing Services</td>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>704.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>English</td>\n",
       "      <td>978-1607857464</td>\n",
       "      <td>https://www.amazon.com/Introduction-Probabilit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Doing Data Science: Straight Talk from the Fro...</td>\n",
       "      <td>\"Cathy ONeil\" and Rachel Schutt</td>\n",
       "      <td>O'Reilly Media, 1st edition</td>\n",
       "      <td>2013-11-19</td>\n",
       "      <td>408.0</td>\n",
       "      <td>26.44</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/Doing-Data-Science-Stra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Mastering PyTorch: Build powerful neural netwo...</td>\n",
       "      <td>Ashish Ranjan Jha and Dr. Gopinath Pillai</td>\n",
       "      <td>Packt Publishing</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>450.0</td>\n",
       "      <td>39.99</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>Foundations of Data Science</td>\n",
       "      <td>Avrim Blum, John Hopcroft, et al.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/Foundations-Data-Scienc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Text as Data: A New Framework for Machine Lear...</td>\n",
       "      <td>Justin Grimmer, Margaret E. Roberts, et al.</td>\n",
       "      <td>Princeton University Press</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>360.0</td>\n",
       "      <td>35.99</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/Text-Data-Framework-Lea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Practical Python Programming for IoT: Build ad...</td>\n",
       "      <td>Gary Smart</td>\n",
       "      <td>Packt Publishing</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>516.0</td>\n",
       "      <td>39.99</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Python for Everybody: Exploring Data in Python 3</td>\n",
       "      <td>Charles R. Severance, Aimee Andrion, et al.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.amazon.com/Python-Everybody-Explor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "605  Continuous Delivery with Docker and Jenkins: C...   \n",
       "711  Data Science Crash Course for Beginners with P...   \n",
       "707  Data Quality Fundamentals: A Practitioner's Gu...   \n",
       "786       Introduction to Probability for Data Science   \n",
       "121  Doing Data Science: Straight Talk from the Fro...   \n",
       "347  Mastering PyTorch: Build powerful neural netwo...   \n",
       "823                        Foundations of Data Science   \n",
       "670  Text as Data: A New Framework for Machine Lear...   \n",
       "464  Practical Python Programming for IoT: Build ad...   \n",
       "32    Python for Everybody: Exploring Data in Python 3   \n",
       "\n",
       "                                          author  \\\n",
       "605                                 Rafal Leszko   \n",
       "711                                          NaN   \n",
       "707              Barr Moses, Lior Gavish, et al.   \n",
       "786                                 Stanley Chan   \n",
       "121              \"Cathy ONeil\" and Rachel Schutt   \n",
       "347    Ashish Ranjan Jha and Dr. Gopinath Pillai   \n",
       "823            Avrim Blum, John Hopcroft, et al.   \n",
       "670  Justin Grimmer, Margaret E. Roberts, et al.   \n",
       "464                                   Gary Smart   \n",
       "32   Charles R. Severance, Aimee Andrion, et al.   \n",
       "\n",
       "                         publisher publishing_date  pages  price language  \\\n",
       "605  Packt Publishing, 2nd edition      2019-05-31  350.0  46.99  English   \n",
       "711              AI Publishing LLC      2020-08-31  314.0  23.48  English   \n",
       "707    O'Reilly Media, 1st edition      2022-10-11  308.0  46.99  English   \n",
       "786   Michigan Publishing Services      2021-11-05  704.0  70.00  English   \n",
       "121    O'Reilly Media, 1st edition      2013-11-19  408.0  26.44  English   \n",
       "347               Packt Publishing      2021-02-12  450.0  39.99  English   \n",
       "823                            NaN             NaT    NaN  51.99      NaN   \n",
       "670     Princeton University Press      2022-03-29  360.0  35.99  English   \n",
       "464               Packt Publishing      2020-11-12  516.0  39.99  English   \n",
       "32                             NaN             NaT  387.0   0.99  English   \n",
       "\n",
       "            ISBN_13                                      complete_link  \\\n",
       "605  978-1838552183  https://www.amazon.com/gp/slredirect/picassoRe...   \n",
       "711  978-1734790146  https://www.amazon.com/Science-Crash-Course-Be...   \n",
       "707             NaN  https://www.amazon.com/Data-Quality-Fundamenta...   \n",
       "786  978-1607857464  https://www.amazon.com/Introduction-Probabilit...   \n",
       "121             NaN  https://www.amazon.com/Doing-Data-Science-Stra...   \n",
       "347             NaN  https://www.amazon.com/gp/slredirect/picassoRe...   \n",
       "823             NaN  https://www.amazon.com/Foundations-Data-Scienc...   \n",
       "670             NaN  https://www.amazon.com/Text-Data-Framework-Lea...   \n",
       "464             NaN  https://www.amazon.com/gp/slredirect/picassoRe...   \n",
       "32              NaN  https://www.amazon.com/Python-Everybody-Explor...   \n",
       "\n",
       "    comments  \n",
       "605      NaN  \n",
       "711      NaN  \n",
       "707      NaN  \n",
       "786      NaN  \n",
       "121      NaN  \n",
       "347      NaN  \n",
       "823      NaN  \n",
       "670      NaN  \n",
       "464      NaN  \n",
       "32       NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4b2e2-732d-4f52-8569-523cbdef4be1",
   "metadata": {},
   "source": [
    "## Export the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c8c6294a-8371-4be3-9631-f464bfbefc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('data_science_books_clean.csv', index=False, na_rep='NaN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
